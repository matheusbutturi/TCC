{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffafa6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Ler os dados\n",
    "df_sample = pd.read_csv('D:/TCC 2/TCC_2/Data/df_sample_2.csv')\n",
    "df_sample_teste = pd.read_csv('D:/TCC 2/TCC_2/Data/df_sample_teste_2.csv')\n",
    "\n",
    "# Dropar as colunas de index\n",
    "df_sample.drop(columns=df_sample.columns[0], axis=1, inplace=True)\n",
    "df_sample_teste.drop(columns=df_sample_teste.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Ordenar os dados\n",
    "df_sample = df_sample.sort_values('nivel_atraso')\n",
    "df_sample_teste = df_sample_teste.sort_values('nivel_atraso')\n",
    "\n",
    "# Salvando o nome das categorias em um objeto\n",
    "target_names = df_sample['nivel_atraso'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79da485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessamento de escalamento da variável quantitativa (entre-1 e 1)\n",
    "scaler = MinMaxScaler()\n",
    "df_sample['peso_carga_scale'] = scaler.fit_transform(df_sample['peso_carga'].values.reshape(-1,1))\n",
    "df_sample.drop('peso_carga', axis=1, inplace=True)\n",
    "\n",
    "df_sample_teste['peso_carga_scale'] = scaler.fit_transform(df_sample_teste['peso_carga'].values.reshape(-1,1))\n",
    "df_sample_teste.drop('peso_carga', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0cb47f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['porto', 'mes', 'tipo_navegacao', 'tipo_operacao', 'mercadoria', 'nivel_atraso', 'peso_carga', 'peso_carga_scale']\n"
     ]
    }
   ],
   "source": [
    "# Selecionar colunas com variaveis categoricas\n",
    "categorical_cols = [cname for cname in df_sample.columns if\n",
    "                    df_sample[cname].nunique() < 20 and \n",
    "                    df_sample[cname].dtype == \"object\"]\n",
    "\n",
    "# Selecionar colunas numericas\n",
    "numerical_cols = [cname for cname in df_sample.columns if \n",
    "                df_sample[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "\n",
    "df_sample = df_sample[my_cols]\n",
    "\n",
    "'''# Preprocessamento dos dados categoricos para análise de correlação\n",
    "df_sample_transformed = pd.get_dummies(df_sample, columns=categorical_cols)\n",
    "\n",
    "df_corr = df_sample_transformed.corr()\n",
    "\n",
    "# Plot da matriz de correlação\n",
    "f, ax = plt.subplots(1, 1, figsize=(20, 20))\n",
    "sns.heatmap(df_corr,\n",
    "            cmap='coolwarm',\n",
    "            ax=ax)\n",
    "ax.set_title('Correlation Matrix', fontsize=12)\n",
    "\n",
    "plt.show()'''\n",
    "\n",
    "print(my_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd81c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação das variaveis target e explicativas\n",
    "y = df_sample.nivel_atraso\n",
    "df_sample.drop('nivel_atraso', axis=1, inplace=True)\n",
    "y_fact = pd.factorize(y)[0]\n",
    "\n",
    "y_teste = df_sample_teste.nivel_atraso\n",
    "df_sample_teste.drop(['nivel_atraso'], axis=1, inplace=True)\n",
    "y_teste_fac = pd.factorize(y_teste)[0]\n",
    "\n",
    "'''# Checando a distribuição de y\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = fig.add_subplot(221)\n",
    "plt.hist(y, bins = 10)\n",
    "ax.set_title(\"Distribuição da variavel dependente do dataset\")\n",
    "\n",
    "plt.show()'''\n",
    "\n",
    "# Separando os dados de treino e validação\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(df_sample, y_fact, \n",
    "                                                                train_size=0.75, test_size=0.25,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# Selecionado as colunas com variaveis categoricas\n",
    "categorical_cols = [cname for cname in X_train_full.columns if\n",
    "                    X_train_full[cname].nunique() < 20 and \n",
    "                    X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Selecionando as colunas com variaveis quantitativas\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "df_sample_teste = df_sample_teste[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad708ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Preprocessamento para os dados numericos\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessamento para os dados categoricos\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "# Juntando os preprocessamentos de ambos os tipos de dados\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fcea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo uma função para plotar as matrizes de confusão\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Matriz de Confusão',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Matriz de Confusão Normalizada\")\n",
    "    else:\n",
    "        print('Matriz de Confusão sem normalização')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Valor Verdadeiro')\n",
    "    plt.xlabel('Valor Predito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8aa2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a clean model\n",
    "model = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('model', model)])\n",
    "\n",
    "#rf_model = pipe.fit(X_train, y_train)\n",
    "\n",
    "# Defining Grid params\n",
    "grid_params = {\n",
    "    'model__n_estimators': [100, 200, 300, 500, 800, 900, 1000],\n",
    "    'model__max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV\n",
    "grid_search = GridSearchCV(pipe, grid_params, cv=3).fit(X_train, y_train)\n",
    "\n",
    "rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Get predictions\n",
    "rf_class_preds = rf_model.predict(X_valid)\n",
    "rf_probs_preds = rf_model.predict_proba(X_valid)\n",
    "\n",
    "# Input the confusions matrix with the results of class preds\n",
    "rf_cm = confusion_matrix(y_valid, rf_class_preds)\n",
    "correct_cm = confusion_matrix(y_valid, y_valid)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "labels = ['Bom', 'Moderado', 'Ruim']\n",
    "a = plt.figure(figsize=(8,8))\n",
    "\n",
    "a.add_subplot(221)\n",
    "plot_confusion_matrix(rf_cm, labels, title='Matriz de Confusão \\n da \\n Floresta Aleatória',\n",
    "                      cmap=plt.cm.Oranges)\n",
    "\n",
    "a.add_subplot(222)\n",
    "plot_confusion_matrix(correct_cm, labels, title='Matriz de Confusão \\n da \\n Floresta Aleatória',\n",
    "                      cmap=plt.cm.Greens)\n",
    "\n",
    "#a.savefig('D:/TCC 2/TCC_2/Imagens/rf_cm.jpg', format='jpg')\n",
    "\n",
    "# Get the metrics from predict\n",
    "rf_f1 = f1_score(y_valid, rf_class_preds, average='weighted')\n",
    "rf_roc = roc_auc_score(y_valid, rf_probs_preds, multi_class='ovr', average='weighted')\n",
    "\n",
    "print(rf_model)\n",
    "print('Área debaixo da curva ROC no Random Forest:', rf_roc)\n",
    "print('F1 Score no Random Forest:', rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe92753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "rf_class_preds_train = rf_model.predict(X_train)\n",
    "rf_probs_preds_train = rf_model.predict_proba(X_train)\n",
    "\n",
    "# Get the metrics from predict\n",
    "rf_f1 = f1_score(y_train, rf_class_preds_train, average='weighted')\n",
    "rf_roc = roc_auc_score(y_train, rf_probs_preds_train, multi_class='ovr', average='weighted')\n",
    "rf_acc = accuracy_score(y_train, rf_class_preds_train)\n",
    "\n",
    "\n",
    "print('Área debaixo da curva ROC no Random Forest:', rf_roc)\n",
    "print('F1 Score no Random Forest:', rf_f1)\n",
    "print('Accuracy rf model:', rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6fd3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# XGB model \n",
    "model_1 = XGBClassifier(verbosity=0, n_estimators=950,learning_rate=0.01,max_depth=8)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "pipe_xgb = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model_1', model_1)])\n",
    "\n",
    "xgb_model = pipe_xgb.fit(X_train, y_train)\n",
    "\n",
    "'''# Defining Grid params\n",
    "grid_params_xgb = {'model_1__n_estimators': [950],\n",
    "                   'model_1__learning_rate': [0.01],\n",
    "                   'model_1__max_depth': [8]}\n",
    "\n",
    "# Define the GridSearchCV\n",
    "grid_search_xgb = GridSearchCV(pipe_xgb, grid_params_xgb, cv=3).fit(X_train, y_train)\n",
    "\n",
    "xgb_model = grid_search_xgb.best_estimator_\n",
    "print(xgb_model)'''\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "xgb_class_preds = xgb_model.predict(X_valid)\n",
    "xgb_probs_preds = xgb_model.predict_proba(X_valid)\n",
    "\n",
    "# Input the confusions matrix with the results of class preds\n",
    "xgb_cm = confusion_matrix(y_valid, xgb_class_preds)\n",
    "\n",
    "# Generates a 100% accuracy matrix\n",
    "correct_cm = confusion_matrix(y_valid, y_valid)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "labels = ['Bom', 'Moderado', 'Ruim']\n",
    "a = plt.figure(figsize=(8,8))\n",
    "\n",
    "a.add_subplot(221)\n",
    "plot_confusion_matrix(xgb_cm, labels, title='Matriz de Confusão \\n Extremo Aumento de  Gradiente',\n",
    "                      cmap=plt.cm.Oranges)\n",
    "\n",
    "#a.savefig('D:/TCC 2/TCC_2/Imagens/xgb_cm.jpg', format='jpg')\n",
    "\n",
    "# Get the metrics from predict\n",
    "xgb_f1 = f1_score(y_valid, xgb_class_preds, average='weighted')\n",
    "xgb_roc = roc_auc_score(y_valid, xgb_probs_preds, multi_class='ovr', average='weighted')\n",
    "\n",
    "print('Área debaixo da curva ROC no XGBoosting:', xgb_roc)\n",
    "print('F1 Score no XGBoosting:', xgb_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab0bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "xgb_class_preds_train = xgb_model.predict(X_train)\n",
    "xgb_probs_preds_train = xgb_model.predict_proba(X_train)\n",
    "\n",
    "# Get the metrics from predict\n",
    "xgb_f1 = f1_score(y_train, xgb_class_preds_train, average='weighted')\n",
    "xgb_roc = roc_auc_score(y_train, xgb_probs_preds_train, multi_class='ovr', average='weighted')\n",
    "xgb_acc = accuracy_score(y_train, xgb_class_preds_train)\n",
    "\n",
    "print('Área debaixo da curva ROC no XGBoosting:', xgb_roc)\n",
    "print('F1 Score no XGBoosting:', xgb_f1)\n",
    "print('Accuracy xgb model:', xgb_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26aadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# LogReg model \n",
    "model_2 = LogisticRegression(C=7, multi_class='multinomial')\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "pipe_logreg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model_2', model_2)])\n",
    "\n",
    "logreg_model = pipe_logreg.fit(X_train, y_train)\n",
    "\n",
    "'''# Defining Grid params\n",
    "grid_params_logreg = {'model_2__penalty': ['l2', 'None'],\n",
    "                      'model_2__C': [0.5, 1, 3, 7],\n",
    "                      'model_2__multi_class': ['multinomial']}\n",
    "\n",
    "# Define the GridSearchCV\n",
    "grid_search_logreg = GridSearchCV(pipe_logreg, grid_params_logreg, cv=3).fit(X_train, y_train)\n",
    "\n",
    "logreg_model = grid_search_logreg.best_estimator_\n",
    "\n",
    "print(logreg_model)'''\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "logreg_class_preds = logreg_model.predict(X_valid)\n",
    "logreg_probs_preds = logreg_model.predict_proba(X_valid)\n",
    "\n",
    "# Input the confusions matrix with the results of class preds\n",
    "logreg_cm = confusion_matrix(y_valid, logreg_class_preds)\n",
    "\n",
    "'''# Generates a 100% accuracy matrix\n",
    "correct_cm = confusion_matrix(y_valid, y_valid)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "labels = ['Bom', 'Moderado', 'Ruim']\n",
    "a = plt.figure(figsize=(8,8))\n",
    "\n",
    "a.add_subplot(222)\n",
    "plot_confusion_matrix(logreg_cm, labels, title='Matriz de Confusão \\n Regressão Logística',\n",
    "                      cmap=plt.cm.Oranges)\n",
    "\n",
    "\n",
    "a.savefig('D:/TCC 2/TCC_2/Imagens/logreg_cm.jpg', format='jpg')'''\n",
    "\n",
    "# Get the metrics from predict\n",
    "logreg_f1 = f1_score(y_valid, logreg_class_preds, average='weighted')\n",
    "logreg_roc = roc_auc_score(y_valid, logreg_probs_preds, multi_class='ovr', average='weighted')\n",
    "\n",
    "print('Área debaixo da curva ROC na Regressão Logística:', logreg_roc)\n",
    "print('F1 Score na Regressão Logística:', logreg_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a00a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of validation data, get predictions\n",
    "logreg_class_preds_train = logreg_model.predict(X_train)\n",
    "logreg_probs_preds_train = logreg_model.predict_proba(X_train)\n",
    "\n",
    "# Get the metrics from predict\n",
    "logreg_f1 = f1_score(y_train, logreg_class_preds_train, average='weighted')\n",
    "logreg_roc = roc_auc_score(y_train, logreg_probs_preds_train, multi_class='ovr', average='weighted')\n",
    "logreg_acc = accuracy_score(y_train, logreg_class_preds_train)\n",
    "\n",
    "print('Área debaixo da curva ROC no XGBoosting:', logreg_roc)\n",
    "print('F1 Score no XGBoosting:', logreg_f1)\n",
    "print('Accuracy xgb model:', logreg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b8dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_train_nn = np.asarray(y_train).astype(np.float64)\n",
    "y_valid_nn = np.asarray(y_valid).astype(np.float64)\n",
    "\n",
    "y_train_nn = tf.convert_to_tensor(y_train_nn, dtype=tf.int64)\n",
    "y_valid_nn = tf.convert_to_tensor(y_valid_nn, dtype=tf.int64)\n",
    "\n",
    "X_train['peso_carga_scale'] = np.asarray(X_train['peso_carga_scale']).astype(np.float64)\n",
    "X_valid['peso_carga_scale'] = np.asarray(X_valid['peso_carga_scale']).astype(np.float64)\n",
    "\n",
    "X_train['peso_carga_scale'] = tf.convert_to_tensor(X_train['peso_carga_scale'], dtype=tf.float64)\n",
    "X_valid['peso_carga_scale'] = tf.convert_to_tensor(X_valid['peso_carga_scale'], dtype=tf.float64)\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_cols)\n",
    "X_valid = pd.get_dummies(X_valid, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9039b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Deep learning model\n",
    "n_inputs = X_train.shape[1]\n",
    "\n",
    "'''# Early stopping method to avoid overfit\n",
    "callback = EarlyStopping(monitor = 'val_loss', patience=200, verbose=1, min_delta=0)'''\n",
    "\n",
    "# Create model\n",
    "nn_model = Sequential([\n",
    "    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with Adam as optimizer and sparse_categorical_crossentropy for final outputs\n",
    "nn_model.compile(Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "nn_model.fit(X_train, y_train_nn, validation_split=0.2, batch_size=100, epochs=1000, shuffle=True, verbose=0)\n",
    "             #callbacks=[callback])\n",
    "\n",
    "# Make predictions in the original x test with the model and turn into classes predictions with np\n",
    "nn_predictions = nn_model.predict(X_valid, batch_size=200, verbose=0)\n",
    "nn_class_predictions = np.argmax(nn_predictions, axis=1)\n",
    "\n",
    "# Input the confusions matrix with the results of classes predicts\n",
    "nn_cm = confusion_matrix(y_valid_nn, nn_class_predictions)\n",
    "correct_cm_nn = confusion_matrix(y_valid_nn, y_valid_nn)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "labels = ['Bom', 'Moderado', 'Ruim']\n",
    "a = plt.figure(figsize=(8,8))\n",
    "\n",
    "a.add_subplot(221)\n",
    "plot_confusion_matrix(nn_cm, labels, title='Modelo de Rede Neural',\n",
    "                      cmap=plt.cm.Oranges)\n",
    "\n",
    "a.add_subplot(224)\n",
    "plot_confusion_matrix(correct_cm_nn, labels, title='Matriz de Confusão \\n 100% de Acurácia',\n",
    "                     cmap=plt.cm.Greens)\n",
    "\n",
    "#a.savefig('D:/TCC 2/TCC_2/Imagens/nn_cm.jpg', format='jpg')\n",
    "\n",
    "# Get the metrics from predict\n",
    "nn_f1 = f1_score(y_valid_nn, nn_class_predictions, average='weighted')\n",
    "nn_roc = roc_auc_score(y_valid_nn, nn_predictions, multi_class='ovr', average='weighted')\n",
    "\n",
    "print('Área debaixo da curva ROC na Rede Neural:', nn_roc)\n",
    "print('F1 Score na Rede Neural:', nn_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b33e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nn_acc = accuracy_score(y_valid_nn, nn_class_predictions)\n",
    "rf_acc = accuracy_score(y_valid, rf_class_preds)\n",
    "logreg_acc = accuracy_score(y_valid, logreg_class_preds)\n",
    "xgb_acc = accuracy_score(y_valid, xgb_class_preds)\n",
    "\n",
    "print('Accuracy nn model:', nn_acc)\n",
    "print('Accuracy logreg model:', logreg_acc)\n",
    "print('Accuracy rf model:', rf_acc)\n",
    "print('Accuracy xgb model:', xgb_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "y = label_binarize(y_fact, classes=[0,1,2])\n",
    "\n",
    "n_classes = 3\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_tr, X_tes, y_tr, y_tes = train_test_split(df_sample, y, train_size=0.75, test_size=0.25, random_state=0)\n",
    "\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X_tr.columns if\n",
    "                    X_tr[cname].nunique() < 20 and \n",
    "                    X_tr[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_tr.columns if \n",
    "                X_tr[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "\n",
    "X_tr = X_tr[my_cols].copy()\n",
    "X_tes = X_tes[my_cols].copy()\n",
    "\n",
    "# classifier\n",
    "clf = OneVsRestClassifier(XGBClassifier(verbosity=0, n_estimators = 950, random_state=0, learning_rate=0.01, max_depth=8))\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('clf', clf)])\n",
    "\n",
    "modelo_xgb = pipe.fit(X_tr, y_tr)\n",
    "\n",
    "y_score = modelo_xgb.predict(X_tes)\n",
    "y_score_probs = modelo_xgb.predict_proba(X_tes)\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "plt.plot(\n",
    "    (0,1),\n",
    "    (0,1),\n",
    "    label=\"Chance (AUC = 0.5)\",\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=1,\n",
    ")\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_tes[:, class_id],\n",
    "        y_score_probs[:, class_id],\n",
    "        name=f\"Curva ROC para categoria: {target_names[class_id]}\",\n",
    "        color=color,\n",
    "        ax=ax,\n",
    "        #plot_chance_level=(class_id == 2)\n",
    "    )\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"Taxa de Falso Positivo\")\n",
    "plt.ylabel(\"Taxa de Verdadeiro Positivo\")\n",
    "plt.title(\"Curvas ROC do modelo de Aumento de Gradiente \\n One-vs-Rest\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig('D:/TCC 2/TCC_2/Imagens/roc_xgb.jpg', format='jpg')\n",
    "\n",
    "# Get the metrics from predict\n",
    "xgb_f1 = f1_score(y_tes, y_score, average='macro')\n",
    "xgb_roc = roc_auc_score(y_tes, y_score_probs, multi_class='ovr', average='macro')\n",
    "xgb_acc = accuracy_score(y_tes, y_score)\n",
    "xgb_precision = precision_score(y_tes, y_score, average='macro')\n",
    "xgb_recall = recall_score(y_tes,y_score, average='macro')\n",
    "\n",
    "print('Área debaixo da curva ROC no XGBoosting:', xgb_roc)\n",
    "print('F1 Score no XGBoosting:', xgb_f1)\n",
    "print('Accuracy xgb model:', xgb_acc)\n",
    "print('precision:', xgb_precision)\n",
    "print('recall:', xgb_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_tr = modelo_xgb.predict(X_tr)\n",
    "y_score_probs_tr = modelo_xgb.predict_proba(X_tr)\n",
    "\n",
    "# Get the metrics from predict\n",
    "xgb_f1_tr = f1_score(y_tr, y_score_tr, average='macro')\n",
    "xgb_roc_tr = roc_auc_score(y_tr, y_score_probs_tr, multi_class='ovr', average='macro')\n",
    "xgb_acc_tr = accuracy_score(y_tr, y_score_tr)\n",
    "\n",
    "print('Área debaixo da curva ROC no XGBoosting:', xgb_roc_tr)\n",
    "print('F1 Score no XGBoosting:', xgb_f1_tr)\n",
    "print('Accuracy xgb model:', xgb_acc_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955134e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
